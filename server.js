// server.js â€” gpt-server-060kc (Render)ìš© [ESM + RAG ì—°ë™ ë³µêµ¬ë³¸]
import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import OpenAI from "openai";

dotenv.config();

console.log("ðŸš€ 060KC gpt-server boot :: with /company-chat (RAG) & /chat");

// ===== í•„ìˆ˜ í™˜ê²½ =====
const PORT = Number(process.env.PORT);
if (!PORT) { console.error("âŒ PORT env missing"); process.exit(1); }

// RAG ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
const RAG_ENDPOINT =
  process.env.RAG_ENDPOINT || "https://zero60kc-rag.onrender.com/ask";

// RAG ížˆíŠ¸ ìµœì†Œ ì ìˆ˜(ì„œë²„ì˜ thresholdì™€ ë§žì¶”ë©´ ê°€ìž¥ ì•ˆì •ì )
const RAG_THRESHOLD = Number(process.env.RAG_THRESHOLD || 0.35);

// ===== ì•± ê³µí†µ =====
const app = express();

app.use(cors({
  origin: [
    "https://www.060kc.com",
    "https://060kc.com",
    "http://localhost:8080",
    "http://127.0.0.1:8080"
  ],
  methods: ["POST", "GET", "OPTIONS"],
  allowedHeaders: ["Content-Type", "Authorization"]
}));
app.use(express.json({ limit: "2mb" }));

// í—¬ìŠ¤ì²´í¬
app.get("/health", (_req, res) => res.json({ ok: true, ts: Date.now() }));

// ì‚¬ëžŒì´ìŒ í…œí”Œë¦¿
function handoffTemplate() {
  return `ì•ˆë…•í•˜ì„¸ìš”! ì €í¬ 060 ì¼€ì´ì”¨ AI ìƒë‹´ì›ìž…ë‹ˆë‹¤.
ì •í™•í•œ ì•ˆë‚´ë¥¼ ìœ„í•´ ë‹´ë‹¹ìž ì—°ê²°ì„ ë°”ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì—°ê²°í•´ ë“œë¦´ê¹Œìš”?
[ë¬¸ì˜: 070-8231-8295, í‰ì¼ 09:00â€“18:00]`;
}

// ----- RAG í˜¸ì¶œ ìœ í‹¸ -----
async function fetchRag(question) {
  try {
    const r = await fetch(RAG_ENDPOINT, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      // ì„œë²„ êµ¬í˜„ì— ë§žê²Œ í•„ìš” íŒŒë¼ë¯¸í„° ìœ ì§€
      body: JSON.stringify({ question, rewrite: true })
    });
    const data = await r.json(); // { answer, hits, bestScore?, found? }
    const hits = Array.isArray(data.hits) ? data.hits : [];
    const bestScore =
      typeof data.bestScore === "number"
        ? data.bestScore
        : (hits[0]?.score ?? 0);

    // ìœ íš¨ì„± íŒë‹¨
    const found =
      (data.found === true) ||
      (hits.length > 0 && bestScore >= RAG_THRESHOLD);

    // ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸(ìƒìœ„ 3~5ê°œ ì •ë„ í•©ì¹˜ê¸°)
    const top = hits.slice(0, 5);
    const context = top.map(h => (h.text || "").trim()).filter(Boolean).join("\n\n");

    return {
      found,
      bestScore,
      answer: (data.answer || "").trim(),
      context
    };
  } catch (e) {
    console.error("[RAG fetch error]", e?.message || e);
    return { found: false, bestScore: 0, answer: "", context: "" };
  }
}

// ----- íšŒì‚¬ ì „ìš© ë¼ìš°íŠ¸ (/company-chat) -----
// 1) ì§ˆë¬¸ ìˆ˜ì‹ 
// 2) RAGì—ì„œ íšŒì‚¬ QA ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
// 3) ì»¨í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ë©´ OpenAIê°€ 'íšŒì‚¬ ë¬¸ì„œë§Œ'ìœ¼ë¡œ ë‹µë³€
// 4) ì—†ìœ¼ë©´ ì‚¬ëžŒì´ìŒ ì•ˆë‚´
app.post("/company-chat", async (req, res) => {
  try {
    const question = (req.body?.question || "").trim();
    if (!question) {
      return res.json({ reply: handoffTemplate(), needs_handoff: true });
    }

    // 1) RAG í˜¸ì¶œ
    const rag = await fetchRag(question);

    // 2) RAGì—ì„œ ë‹µì„ ì§ì ‘ ì£¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ê°€ìž¥ í™•ì‹¤)
    if (rag.found && rag.answer && rag.answer.replace(/\s/g, "") !== "ìžë£Œì—ì—†ìŒ") {
      return res.json({ reply: rag.answer, needs_handoff: false });
    }

    // 3) ì§ì ‘ ë‹µì´ ì—†ë”ë¼ë„ ì»¨í…ìŠ¤íŠ¸ê°€ ìžˆìœ¼ë©´, ì»¨í…ìŠ¤íŠ¸ ì œí•œ ë‹µë³€ ì‹œë„
    if (rag.found && rag.context) {
      const systemPrompt = `
ë‹¹ì‹ ì€ 060 ì¼€ì´ì”¨(060KC) íšŒì‚¬ ë¬¸ì„œ ì „ìš© ìƒë‹´ì›ìž…ë‹ˆë‹¤.
ì•„ëž˜ CONTEXT(íšŒì‚¬ ìžë£Œ)ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤.
CONTEXTì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì •í•˜ì§€ ë§ê³  ë‹¤ìŒ ë¬¸êµ¬ë¡œë§Œ ë‹µí•©ë‹ˆë‹¤:
"ìžë£Œì— ì—†ìŠµë‹ˆë‹¤. ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
ë¬¸ì²´: ì •ì¤‘í•˜ê³  ê°„ê²°. ê³¼ìž¥/ì¶”ì¸¡/ì¼ë°˜ì§€ì‹ ì‚¬ìš© ê¸ˆì§€.
`.trim();

      const userPrompt = `
[QUESTION]
${question}

[CONTEXT]
${rag.context}
`.trim();

      const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
      const r = await openai.chat.completions.create({
        model: process.env.CHAT_MODEL || "gpt-4o-mini",
        temperature: 0.2,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt }
        ]
      });

      const reply = r.choices?.[0]?.message?.content?.trim() || "";
      if (reply && !/ìžë£Œì— ì—†ìŠµë‹ˆë‹¤/i.test(reply)) {
        return res.json({ reply, needs_handoff: false });
      }
    }

    // 4) ì—¬ê¸°ê¹Œì§€ ëª» ì°¾ìœ¼ë©´ ì‚¬ëžŒì´ìŒ
    return res.json({ reply: handoffTemplate(), needs_handoff: true });
  } catch (e) {
    console.error("[/company-chat] error:", e?.message || e);
    return res.status(500).json({ reply: handoffTemplate(), needs_handoff: true });
  }
});

// (ì˜µì…˜) ë²”ìš© ì±„íŒ… ê·¸ëŒ€ë¡œ ìœ ì§€
app.post("/chat", async (req, res) => {
  try {
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    const userMessage = req.body?.message || "";
    const r = await openai.chat.completions.create({
      model: process.env.CHAT_MODEL || "gpt-4o-mini",
      temperature: 0.3,
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: userMessage }
      ]
    });
    res.json({ reply: r.choices?.[0]?.message?.content ?? "" });
  } catch (e) {
    console.error("[/chat] error:", e?.message || e);
    res.status(500).json({ error: "GPT ì„œë²„ ì˜¤ë¥˜ ë°œìƒ" });
  }
});

app.listen(PORT, "0.0.0.0", () => {
  console.log(`âœ… company-chat ONLINE on 0.0.0.0:${PORT}`);
});
