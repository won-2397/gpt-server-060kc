// server.js â€” gpt-server-060kc (Render)ìš© [ESM ë²„ì „]
import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import OpenAI from "openai";

dotenv.config();

console.log("ðŸš€ 060KC gpt-server boot :: with /company-chat route");

const app = express();

// PORT (Render í•„ìˆ˜)
const PORT = Number(process.env.PORT);
if (!PORT) { console.error("âŒ PORT env missing"); process.exit(1); }

// CORS: ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ë„ë©”ì¸ë§Œ
app.use(cors({
  origin: [
    "https://www.060kc.com",
    "https://060kc.com",
    "http://localhost:8080",
    "http://127.0.0.1:8080"
  ],
  methods: ["POST","GET","OPTIONS"],
  allowedHeaders: ["Content-Type","Authorization"]
}));
app.use(express.json({ limit: "2mb" }));

// í—¬ìŠ¤ì²´í¬
app.get("/health", (_req, res) => res.json({ ok: true, ts: Date.now() }));

// ì‚¬ëžŒì´ìŒ í…œí”Œë¦¿
function handoffTemplate() {
  return `ì•ˆë…•í•˜ì„¸ìš”! ì €í¬ 060 ì¼€ì´ì”¨ AI ìƒë‹´ì›ìž…ë‹ˆë‹¤.
ì •í™•í•œ ì•ˆë‚´ë¥¼ ìœ„í•´ ë‹´ë‹¹ìž ì—°ê²°ì„ ë°”ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì—°ê²°í•´ ë“œë¦´ê¹Œìš”?
[ë¬¸ì˜: 070-8231-8295, í‰ì¼ 09:00â€“18:00]`;
}

// ì»¨í…ìŠ¤íŠ¸ ì „ìš© ìƒì„± ë¼ìš°íŠ¸
app.post("/company-chat", async (req, res) => {
  try {
    const question = (req.body?.question || "").trim();
    const context  = (req.body?.context  || "").trim();
    if (!question || !context) {
      return res.json({ reply: handoffTemplate(), needs_handoff: true });
    }

    const systemPrompt = `
ë‹¹ì‹ ì€ 060 ì¼€ì´ì”¨(060KC) íšŒì‚¬ ë¬¸ì„œ ì „ìš© ìƒë‹´ì›ìž…ë‹ˆë‹¤.
ì•„ëž˜ CONTEXT(íšŒì‚¬ ìžë£Œ)ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤.
CONTEXTì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì •í•˜ì§€ ë§ê³  ë‹¤ìŒ ë¬¸êµ¬ë¡œë§Œ ë‹µí•©ë‹ˆë‹¤:
"ìžë£Œì— ì—†ìŠµë‹ˆë‹¤. ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
ë¬¸ì²´: ì •ì¤‘í•˜ê³  ê°„ê²°. ê³¼ìž¥/ì¶”ì¸¡/ì¼ë°˜ì§€ì‹ ì‚¬ìš© ê¸ˆì§€.
`.trim();

    const userPrompt = `
[QUESTION]
${question}

[CONTEXT]
${context}
`.trim();

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    const r = await openai.chat.completions.create({
      model: process.env.CHAT_MODEL || "gpt-4o-mini",
      temperature: 0.2,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user",   content: userPrompt }
      ]
    });

    const reply = r.choices?.[0]?.message?.content?.trim() || "";
    if (!reply || /ìžë£Œì— ì—†ìŠµë‹ˆë‹¤/i.test(reply)) {
      return res.json({ reply: handoffTemplate(), needs_handoff: true });
    }
    return res.json({ reply, needs_handoff: false });
  } catch (e) {
    console.error("[/company-chat] error:", e?.message || e);
    return res.status(500).json({ reply: handoffTemplate(), needs_handoff: true });
  }
});

// (ì˜µì…˜) ë²”ìš© ì±„íŒ…
app.post("/chat", async (req, res) => {
  try {
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    const userMessage = req.body?.message || "";
    const r = await openai.chat.completions.create({
      model: process.env.CHAT_MODEL || "gpt-4o-mini",
      temperature: 0.3,
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user",   content: userMessage }
      ]
    });
    res.json({ reply: r.choices?.[0]?.message?.content ?? "" });
  } catch (e) {
    console.error("[/chat] error:", e?.message || e);
    res.status(500).json({ error: "GPT ì„œë²„ ì˜¤ë¥˜ ë°œìƒ" });
  }
});

app.listen(PORT, "0.0.0.0", () => {
  console.log(`âœ… company-chat ONLINE on 0.0.0.0:${PORT}`);
});
